name: Price-IQ â€” build & publish

on:
  schedule:
    - cron: "0 */4 * * *"           # run every 4 hours
  workflow_dispatch: {}

permissions:
  contents: write
  pages: write
  id-token: write
  pull-requests: write

concurrency:
  group: priceiq-build
  cancel-in-progress: true

env:
  OUTPUT_DIR: docs/data/derived
  NB_IN: scrape+formula.ipynb
  PYTHONUNBUFFERED: "1"

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-msplaywright-v1

      # --- Always ensure ipykernel + papermill/jupyter exist, even if requirements.txt is present
      - name: Install deps & register kernel
        run: |
          set -e
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Ensure CI has a working kernelspec and notebook tooling
          pip install --upgrade ipykernel jupyter papermill nbformat nbclient
          # (if your requirements.txt doesn't include these libs, uncomment next line)
          # pip install pandas numpy pyarrow beautifulsoup4 lxml requests scikit-learn playwright
          python -m ipykernel install --user --name python3 --display-name "Python 3"
          python -m jupyter kernelspec list

      - name: Install Playwright Chromium (with OS deps)
        run: |
          python -m playwright install --with-deps chromium

      - name: Prepare output dirs
        run: |
          mkdir -p docs/data/derived docs/data/history docs/data/latest docs
          echo > docs/.nojekyll

      - name: Execute notebook
        env:
          NB_IN: ${{ env.NB_IN }}
          OUTPUT_DIR: ${{ env.OUTPUT_DIR }}
          HEADLESS: "1"   # make notebook CI-safe (skip interactive EDA)
        run: |
          set -e
          mkdir -p artifacts "$OUTPUT_DIR"
          NB="${NB_IN}"
          # fallback to first notebook if name changes
          [ -f "$NB" ] || NB="$(git ls-files '*.ipynb' | head -n 1)"
          echo "Using notebook: $NB"
          python -m papermill "$NB" "artifacts/$(basename "${NB%.ipynb}")_out.ipynb" \
            -k python3 \
            -p OUTPUT_DIR "$OUTPUT_DIR" \
            -p HEADLESS "$HEADLESS"

      - name: Commit dashboard data (derived + history + latest)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
      
          # 1) Stage changes FIRST (prevents 'cannot pull with rebase' error)
          git add docs/data/derived docs/data/history docs/data/latest docs/.nojekyll || true
      
          # 2) If nothing staged, bail out early
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
      
          # 3) Commit
          git commit -m "Price-IQ: update data (derived + history + latest)"
      
          # 4) Update local branch in case remote moved; reapply our commit cleanly
          git pull --rebase --autostash
      
          # 5) Push
          git push






